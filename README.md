Mongoâ€¯â†’â€¯Snowflake â€¢ Pipeline ETL Incremental com Airflow

Resumo rÃ¡pidoExemplo pronto para produÃ§Ã£o que extrai apenas os documentos novos/atualizados de uma coleÃ§Ã£o MongoDB, gera arquivos Parquet e carrega tudo em uma stage do Snowflake.Tabela de controle garante idempotÃªncia e um task final suspende o warehouse para economizar crÃ©ditos.Todas as credenciais e nomes de objetos ficam fora do cÃ³digoâ€‘fonte (Connections e Variables do Airflow).

âš™ï¸ VisÃ£o Geral

MongoDB â”€â”€â–¶ Airflow (DAG) â”€â”€â–¶ Stage Snowflake â”€â”€â–¶ Tabela de Controle
   â–²                                   â”‚
   â””â”€â”€ filtro watermark (âˆ†) â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Incremental: consulta apenas documentos com dataalteracao > Ãºltimo upload.

Flatten: normaliza subâ€‘documentos metadata e funcionario.

Parquet + PUT: performance e compressÃ£o nativas do Snowflake.

Controle: grava nome do arquivo, data de upload, quantidade de linhas e flag de processado.

Custo: suspende o warehouse Snowflake ao final da carga.

ğŸ—‚ Estrutura do RepositÃ³rio

.
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ dag_mongo_to_snowflake.py   # DefiniÃ§Ã£o do DAG
â”œâ”€â”€ tasks/
â”‚   â”œâ”€â”€ tasks.py                    # FunÃ§Ãµes de ETL chamadas pelo DAG
â”‚   â””â”€â”€ utils.py                    # Helpers (credenciais, parsing)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md                       # (este arquivo)

Ajuste o caminho do diretÃ³rio dags/ de acordo com a variÃ¡vel de ambienteAIRFLOW__CORE__DAGS_FOLDER do seu deploy do Airflow.

ğŸ›  Tecnologias Principais

Camada

Ferramenta/Lib

FunÃ§Ã£o

OrquestraÃ§Ã£o

Apache Airflowâ€¯2.8+

Agendamento, retries, logs

Fonte

MongoDB + pymongo

Consulta incremental

TransformaÃ§Ã£o

pandas + pytz

Flatten + tratamento de time zone

Destino

Snowflake (snowflakeâ€‘connector-python)

Stage + tabela de controle

ConfiguraÃ§Ã£o

Airflow Connections/Variables

Segredos e parÃ¢metros externos

ğŸ“‹ PrÃ©â€‘requisitos

Python 3.9+

Airflow 2.8+ com o provider snowflake instalado

Acesso de leitura a um cluster MongoDB

UsuÃ¡rio/role Snowflake com permissÃ£o de PUT, INSERT, UPDATE e ALTER WAREHOUSE

ğŸš€ Como Usar

1. Clonar o projeto

git clone https://github.com/<seuâ€‘org>/mongo-to-snowflake.git
cd mongo-to-snowflake

2. Instalar dependÃªncias

pip install -r requirements.txt

3. Criar conexÃµes e variÃ¡veis no Airflow

Tipo

Chave/Nome

Exemplo / ObservaÃ§Ã£o

Connection

snowflake_default

account, user, warehouse, database, schemaâ€¦

Variable

mongo_credentials

{"mongo_uri":"mongodb://<user>:<pwd>@host:27017","mongo_db":"mydb","mongo_collection":"minha_colecao"}

Variable

snowflake_schema_stage

@STAGE.DATALAKE

Variable

snowflake_schema_control

BRONZE

Variable

snowflake_timezone

America/Sao_Paulo (padrÃ£o)

Importante: nÃ£o suba credenciais reais para o Git.

4. Ativar a DAG

Copie dags/dag_mongo_to_snowflake.py para o diretÃ³rio de DAGs do Airflow.

No UI, habilite o toggle da DAG.

Dispare manualmente ou aguarde o agendamento (@daily por padrÃ£o).

ğŸ” VisÃ£o de CÃ³digo

DAG (simplificado)

with DAG(
    dag_id="mongo_to_sf_incremental",
    schedule_interval="@daily",
    start_date=datetime(2024, 1, 1),
    catchup=False,
    default_args={
        "owner": "airflow",
        "retries": 5,
        "retry_delay": timedelta(minutes=2)
    },
    tags=["etl", "mongo", "snowflake"]
) as dag:
    arquivo   = extract_and_ingest()
    atualizar = update_processed_flags(arquivo)
    suspender = stop_warehouse()

    arquivo >> atualizar >> suspender

extract_and_ingest() â€“Â extrai, normaliza, grava Parquet e faz PUT.

update_processed_flags() â€“Â marca o arquivo como processado.

stop_warehouse() â€“Â suspende o warehouse (opcional).

ğŸ§© PersonalizaÃ§Ã£o

Precisa mudar

Onde alterar

Campo de watermark

tasks.py â†’ get_mongo_documents()

Campos aninhados adicionais

tasks.py â†’ process_documents()

Formato de arquivo

tasks.py â†’ save_dataframe_to_parquet()

FrequÃªncia da DAG

dag_mongo_to_snowflake.py â†’ schedule_interval

Suspender WH

Remover/editar stop_warehouse() se a polÃ­tica for diferente

â— Problemas Comuns

Sintoma

Causa provÃ¡vel

CorreÃ§Ã£o

â€œNenhum documento novoâ€

Coluna/Timezone incorretos

Verifique filtro e fuso horÃ¡rio

MemoryError ao ler Mongo

DF grande demais

Paginar com batch_size() ou usar Dask

Warehouse nÃ£o suspende

Uso concorrente

Ajuste stop_warehouse() ou multiâ€‘cluster

PUT lento

Largura de banda da rede

Stage externa (S3/GCS) ou compressÃ£o maior

ğŸ“„ LicenÃ§a

DistribuÃ­do sob a MIT License.
